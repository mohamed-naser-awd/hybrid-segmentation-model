import torch
from torch.utils.data import Dataset
from torchvision.datasets import OxfordIIITPet
import torchvision.transforms.functional as TF
from torchvision.transforms import InterpolationMode
import numpy as np
import os
from PIL import Image
from utils import profile_block


class P3M10kDataset(Dataset):
    def __init__(self, img_dir, mask_dir, size=640, **kw):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.size = size
        self.images = sorted(os.listdir(img_dir))

    def __len__(self):
        return len(self.images)

    def get_image(self, idx):
        img_name = self.images[idx]

        img = Image.open(os.path.join(self.img_dir, img_name)).convert("RGB")
        try:
            mask = Image.open(
                os.path.join(self.mask_dir, img_name.replace("jpg", "png"))
            ).convert("L")
        except FileNotFoundError:
            mask = Image.open(os.path.join(self.mask_dir, img_name)).convert("L")

        img = TF.resize(
            img, (self.size, self.size), interpolation=InterpolationMode.BILINEAR
        )
        mask = TF.resize(
            mask, (self.size, self.size), interpolation=InterpolationMode.NEAREST
        )

        img = TF.to_tensor(img)
        mask = torch.from_numpy(np.array(mask)).long()  # Ù„Ùˆ multi-class

        return img, mask

    def __getitem__(self, idx):
        return self.get_image(idx)
        return profile_block("get p3m10k item", self.get_image, idx)

class P3MMemmapDataset(Dataset):
    def __init__(self, mmap_path, mask_mmap_path, N=None):
        self.mmap_path = mmap_path
        self.mask_mmap_path = mask_mmap_path
        self.N = N

        self.imgs = None
        self.masks = None  # ğŸ‘ˆ Ù‡Ù†ØªÙØªØ­ Ø£ÙˆÙ„ Ù…Ø±Ø© ÙÙ‚Ø· Ø¯Ø§Ø®Ù„ worker

    def _init_memmap(self):
        C = 3
        N = self.N
        H = W = 640

        if self.imgs is None:
            self.imgs = np.memmap(
                self.mmap_path,
                dtype="float16",
                mode="r",
                shape=(N, C, H, W),
            )

            print(f"images path: {self.mmap_path}")
            print(f"masks path: {self.mask_mmap_path}")

            self.masks = np.memmap(
                self.mask_mmap_path,
                dtype="float16",
                mode="r",
                shape=(N, 1, H, W),
            )

    def __getitem__(self, idx):
        return profile_block("get p3m10k item", self.get_item, idx)

    def get_item(self, idx):
        self._init_memmap()  # <--- ÙŠØªÙØªØ­ Ù„ÙƒÙ„ ÙˆÙˆØ±ÙƒØ± Ù„ÙˆØ­Ø¯Ù‡ Ø£ÙˆÙ„ Ù…Ø±Ø©
        img = torch.from_numpy(self.imgs[idx])
        mask = torch.from_numpy(self.masks[idx])
        return img, mask

    def __len__(self):
        return self.N


class PetSegmentationDataset(Dataset):
    """
    Ø¯Ø§ØªØ§Ø³ÙŠØª Ø¨Ø³ÙŠØ·Ø© ÙÙˆÙ‚ Oxford-IIIT Pet:
    - Ø¨ØªØ­ÙˆÙ„ Ø§Ù„Ù…Ø§Ø³Ùƒ Ù„ØªØ±ÙŠÙ†Ø§Ø±ÙŠ â†’ Ø¨ÙŠÙ†Ø§Ø±ÙŠ (pet vs background)
    - Ø¨ØªØ¹Ù…Ù„ resize Ù„Ù„Ù€ image ÙˆØ§Ù„Ù€ mask Ù„Ù€ 640x640 Ø¹Ø´Ø§Ù† ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨ØªØ§Ø¹Ùƒ
    """

    def __init__(self, root: str, image_size: int = 640, split: str = "trainval"):
        super().__init__()
        self.image_size = image_size

        # target_types="segmentation" Ø¹Ø´Ø§Ù† ÙŠØ¯ÙŠÙƒ Ø§Ù„Ù…Ø§Ø³Ùƒ Ù…Ø´ Ø§Ù„ÙƒÙ„Ø§Ø³
        self.base_dataset = OxfordIIITPet(
            root=root,
            split=split,
            target_types="segmentation",
            download=True,
        )

    def __len__(self):
        return len(self.base_dataset)

    def __getitem__(self, idx):
        image, seg = self.base_dataset[idx]  # image: PIL, seg: PIL mask (trimap)

        # --- resize image ---
        image = TF.resize(
            image,
            (self.image_size, self.image_size),
            interpolation=InterpolationMode.BILINEAR,
        )
        image = TF.to_tensor(image)  # (3, H, W), [0,1]

        # --- convert & resize mask ---
        seg = TF.resize(
            seg,
            (self.image_size, self.image_size),
            interpolation=InterpolationMode.NEAREST,
        )
        seg_np = np.array(seg)

        # ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª Ø¯ÙŠ Ø§Ù„Ù…Ø§Ø³Ùƒ trimap (background / pet / border):contentReference[oaicite:1]{index=1}
        # Ù‡Ù†Ø®Ù„ÙŠ Ø£ÙŠ Ø­Ø§Ø¬Ø© Ù…Ø´ background = 1
        # ØºØ§Ù„Ø¨Ù‹Ø§ background = 1, pet = 2, border = 3
        mask_np = (seg_np != 1).astype("float32")

        mask = torch.from_numpy(mask_np)  # (H, W), float32 {0,1}

        return image.float(), mask.float()
